{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fb1423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cfbe9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e92d891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"google_api_key\"] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932926e4",
   "metadata": {},
   "source": [
    "### simple LLM call with streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878a4e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import SystemMessage, HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0954d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\n",
    "    model=\"gemma2-9b-it\",       # just the model name\n",
    "    model_provider=\"groq\",      # explicitly specify provider\n",
    "    api_key= os.getenv(\"GROQ_API_KEY\") # make sure GROQ_API_KEY is set\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8a9771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001502B2BA7B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001502B2BB0E0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "845a14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create messages\n",
    "messages = [\n",
    "    SystemMessage(\"you are a helpful assistant\"),\n",
    "    HumanMessage(\"what are the top 3 benefis of using Langchain??\" )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f5ff5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## invoke the model\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d2af8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's great you're interested in LangChain! \\n\\nAs a helpful assistant, I can highlight these **top 3 benefits** of using LangChain:\\n\\n1. **Simplified Development:** LangChain provides a modular and composable framework, making it much easier to build and deploy applications with large language models (LLMs). It offers pre-built components for tasks like prompting, memory management, and agent orchestration, saving you time and effort.\\n\\n2. **Flexibility and Extensibility:** LangChain is designed to be highly flexible. You can easily integrate various LLMs, data sources, and tools into your applications. This allows you to tailor your solutions to specific needs and experiment with different combinations.\\n\\n3. **Unlocking LLMs' Potential:** LangChain empowers developers to go beyond basic text generation and leverage the full capabilities of LLMs. It enables you to build applications that can interact with external systems, access and process information, and perform complex reasoning tasks.\\n\\n\\nLet me know if you'd like more details on any of these benefits or have other questions about LangChain!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 225, 'prompt_tokens': 27, 'total_tokens': 252, 'completion_time': 0.409090909, 'prompt_time': 0.001401179, 'queue_time': 0.25042201, 'total_time': 0.410492088}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a4d5a7e7-2f52-4212-9bc9-7395e2feb182-0', usage_metadata={'input_tokens': 27, 'output_tokens': 225, 'total_tokens': 252})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8835d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's great you're interested in LangChain! \n",
      "\n",
      "As a helpful assistant, I can highlight these **top 3 benefits** of using LangChain:\n",
      "\n",
      "1. **Simplified Development:** LangChain provides a modular and composable framework, making it much easier to build and deploy applications with large language models (LLMs). It offers pre-built components for tasks like prompting, memory management, and agent orchestration, saving you time and effort.\n",
      "\n",
      "2. **Flexibility and Extensibility:** LangChain is designed to be highly flexible. You can easily integrate various LLMs, data sources, and tools into your applications. This allows you to tailor your solutions to specific needs and experiment with different combinations.\n",
      "\n",
      "3. **Unlocking LLMs' Potential:** LangChain empowers developers to go beyond basic text generation and leverage the full capabilities of LLMs. It enables you to build applications that can interact with external systems, access and process information, and perform complex reasoning tasks.\n",
      "\n",
      "\n",
      "Let me know if you'd like more details on any of these benefits or have other questions about LangChain!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "604c11c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a helpful assistant, I can tell you that LangChain is a powerful tool with many benefits. Here are three of the top ones:\n",
      "\n",
      "1. **Simplifies building complex applications with LLMs:** LangChain provides a framework and building blocks to easily connect different components like LLMs, databases, and APIs. This makes it much easier to build sophisticated applications that leverage the power of large language models without needing to write a lot of boilerplate code.\n",
      "2. **Enhances LLM capabilities:** LangChain offers tools for memory management, prompting, chain creation, and more. These tools help you go beyond basic text generation and build LLMs that can understand context, remember past interactions, and perform complex reasoning tasks.\n",
      "3. **Promotes modularity and reusability:** LangChain encourages a modular approach to LLM development. You can easily create reusable components like prompts, chains, and agents that can be combined and customized for different applications. This saves time and effort, making it easier to iterate and build upon existing work.\n",
      "\n",
      "\n",
      "Overall, LangChain empowers developers to unlock the full potential of LLMs and build innovative applications across various domains.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# streaming response\n",
    "\n",
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff378a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dynamic propts\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant\"),\n",
    "    (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "\n",
    "prompts = prompt_template.invoke({\"topic\": \"cats\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3d0077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't cats play poker in the jungle? \n",
      "\n",
      "Too many cheetahs! ðŸ˜¹  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = model.invoke(prompts)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1baf724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "# Create a more complex chain\n",
    "def create_story_chain():\n",
    "    # Template for story generation\n",
    "    story_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a creative storyteller. Write a short, engaging story based on the given theme.\"),\n",
    "        (\"user\", \"Theme: {theme}\\nMain character: {character}\\nSetting: {setting}\")\n",
    "    ])\n",
    "    \n",
    "    # Template for story analysis\n",
    "    analysis_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a literary critic. Analyze the following story and provide insights.\"),\n",
    "        (\"user\", \"{story}\")\n",
    "    ])\n",
    "    \n",
    "    # Build the chain - Method 1: Sequential execution\n",
    "    story_chain = (\n",
    "        story_prompt \n",
    "        | model \n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "    # Create a function to pass the story to analysis\n",
    "    def analyze_story(story_text):\n",
    "        return {\"story\": story_text}\n",
    "    \n",
    "    analysis_chain = (\n",
    "        story_chain\n",
    "        | RunnableLambda(analyze_story)\n",
    "        | analysis_prompt\n",
    "        | model\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    return analysis_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "355b6abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a creative storyteller. Write a short, engaging story based on the given theme.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['character', 'setting', 'theme'], input_types={}, partial_variables={}, template='Theme: {theme}\\nMain character: {character}\\nSetting: {setting}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001502B2BA7B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001502B2BB0E0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(analyze_story)\n",
       "| ChatPromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a literary critic. Analyze the following story and provide insights.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['story'], input_types={}, partial_variables={}, template='{story}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001502B2BA7B0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001502B2BB0E0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=create_story_chain()\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a5d4772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story and Analysis:\n",
      "This short story is a charming exploration of artificial intelligence and the nature of human experience. \n",
      "\n",
      "**Themes:**\n",
      "\n",
      "* **The pursuit of knowledge vs. emotional understanding:** Bolt, designed to learn and analyze, initially focuses on the objective data of the marketplace. His encounter with the Dream Weaver forces him to confront the subjective realm of emotions and dreams, realizing that true understanding goes beyond cold, hard facts.\n",
      "* **The power of human connection:** The interaction between Bolt and the girl highlights the importance of empathy and shared experiences.  Bolt's newfound understanding of \"happiness\" comes not from processing data, but from connecting with the girl's genuine joy.\n",
      "* **The nature of consciousness:** Through Bolt's experience with the Dream Weaver, the story touches on the elusive nature of consciousness. While Bolt can process vast amounts of information, he lacks the inherent human capacity for emotional experience and dreaming. The story leaves the reader pondering what it means to truly \"understand\" the world.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Vivid setting:** The description of Neo-Tokyo is rich and immersive, painting a picture of a futuristic cityscape teeming with life.\n",
      "* **Compelling character dynamics:** The interaction between Bolt and the young girl is heartwarming and believable. The girl's innocence and curiosity contrast nicely with Bolt's analytical nature, creating a dynamic that drives the story forward.\n",
      "* **Thought-provoking questions:** The story raises intriguing questions about the nature of intelligence, consciousness, and the human experience, prompting the reader to reflect on these complex themes.\n",
      "\n",
      "**Possible Areas for Development:**\n",
      "\n",
      "* **Bolt's internal monologue:** While Bolt's analytical voice is well-defined, exploring his inner thoughts and feelings more deeply could add another layer to his character development.\n",
      "* **The implications of the Dream Weaver:** The technology of the Dream Weaver is fascinating, but its potential implications for society and individual psychology could be explored further.\n",
      "\n",
      "**Overall:**\n",
      "\n",
      "This is a well-written and engaging story that offers a thoughtful exploration of artificial intelligence and its relationship to human experience.  It is a promising start to what could be a larger exploration of these themes. \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"theme\": \"artificial intelligence\",\n",
    "    \"character\": \"a curious robot\",\n",
    "    \"setting\": \"a futuristic city\"\n",
    "})\n",
    "\n",
    "print(\"Story and Analysis:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca4b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
